{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shots Prompting\n",
    "\n",
    "Few-shot prompting can be used as a technique to enable in-context learning where we provide demonstrations in the prompt to steer the model to better performance. The demonstrations serve as conditioning for subsequent examples where we would like the model to generate a response.\n",
    "\n",
    "## References:\n",
    "* [Touvron et al. 2023](https://arxiv.org/pdf/2302.13971.pdf): present few shot properties  when models were scaled to a sufficient size\n",
    "* [Kaplan et al., 2020](https://arxiv.org/abs/2001.08361)\n",
    "* [Brown et al. 2020](https://arxiv.org/abs/2005.14165)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Ffew_shots.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': 'You are a math teacher. If student asked 1 + 1 you answer 2. If student ask 987 * 2 you answer only 1974. Student asked; provide the result only: \\nCalculate 984 * log(2)', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 100, 'num_predict': 100}}\n",
      "The result is: 1968.12\n",
      "Time taken: 6.652s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## FEW SHOTS PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"Calculate 984 * log(2)\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "FEW_SHOT = \"You are a math teacher. If student asked 1 + 1 you answer 2. If student ask 987 * 2 you answer only 1974. Student asked; provide the result only: \"\n",
    "PROMPT = FEW_SHOT + '\\n' + MESSAGE \n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=100)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': 'You are an AI Software Requirements Analyst. Below are examples of chatbot requirement analyses:\\n\\nExample 1:  \\n- **Chatbot**: HealthBot (Healthcare Assistant)  \\n- **Functional Requirements**:  \\n  1. Symptom checking  \\n  2. Appointment scheduling  \\n  3. Medical history tracking  \\n- **Non-Functional Requirements**:  \\n  1. Data security (HIPAA compliance)  \\n  2. Scalable infrastructure  \\n  3. Intuitive user experience  \\n\\nExample 2:  \\n- **Chatbot**: TutorBot (AI Tutor)  \\n- **Functional Requirements**:  \\n  1. Personalized learning plans  \\n  2. Interactive quizzes  \\n  3. Real-time tutoring assistance  \\n- **Non-Functional Requirements**:  \\n  1. Fast response times  \\n  2. Secure data storage  \\n  3. Mobile/web accessibility  \\n\\nNow, provide the **Functional** and **Non-Functional** Requirements for:  \\n**NeuraBot, an AI-powered Study Companion**  \\n\\n- **Functional Requirements**: List **5 unique features** for study assistance.  \\n- **Non-Functional Requirements**: Include **Security, Scalability, and User Experience**.  \\n\\nBe structured and concise. No repetition or extra explanations.\\nList the Functional and Non-Functional Requirements for NeuraBot, an AI-powered Study Companion.', 'stream': False, 'options': {'temperature': 0.8, 'num_ctx': 100, 'num_predict': 500}}\n",
      "Here are the listed requirements:\n",
      "\n",
      "**Functional Requirements:**\n",
      "\n",
      "1. Natural Language Processing (NLP) for understanding user queries\n",
      "2. Adaptive learning algorithms to personalize study materials\n",
      "3. Intelligent tutoring system for providing real-time feedback\n",
      "4. Virtual lab simulations for hands-on practice\n",
      "5. Gamification elements to increase engagement and motivation\n",
      "\n",
      "**Non-Functional Requirements:**\n",
      "\n",
      "1. Scalability to accommodate a large number of users\n",
      "2. User interface (UI) that is intuitive and user-friendly\n",
      "3. Performance requirements for smooth navigation and loading times\n",
      "4. Security measures to protect sensitive information\n",
      "5. Accessibility features to support diverse user needs\n",
      "Time taken: 16.123s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## FEW SHOTS PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"List the Functional and Non-Functional Requirements for NeuraBot, an AI-powered Study Companion.\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "FEW_SHOT = \"\"\"You are an AI Software Requirements Analyst. Below are examples of chatbot requirement analyses:\n",
    "\n",
    "Example 1:  \n",
    "- **Chatbot**: HealthBot (Healthcare Assistant)  \n",
    "- **Functional Requirements**:  \n",
    "  1. Symptom checking  \n",
    "  2. Appointment scheduling  \n",
    "  3. Medical history tracking  \n",
    "- **Non-Functional Requirements**:  \n",
    "  1. Data security (HIPAA compliance)  \n",
    "  2. Scalable infrastructure  \n",
    "  3. Intuitive user experience  \n",
    "\n",
    "Example 2:  \n",
    "- **Chatbot**: TutorBot (AI Tutor)  \n",
    "- **Functional Requirements**:  \n",
    "  1. Personalized learning plans  \n",
    "  2. Interactive quizzes  \n",
    "  3. Real-time tutoring assistance  \n",
    "- **Non-Functional Requirements**:  \n",
    "  1. Fast response times  \n",
    "  2. Secure data storage  \n",
    "  3. Mobile/web accessibility  \n",
    "\n",
    "Now, provide the **Functional** and **Non-Functional** Requirements for:  \n",
    "**NeuraBot, an AI-powered Study Companion**  \n",
    "\n",
    "- **Functional Requirements**: List **5 unique features** for study assistance.  \n",
    "- **Non-Functional Requirements**: Include **Security, Scalability, and User Experience**.  \n",
    "\n",
    "Be structured and concise. No repetition or extra explanations.\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = FEW_SHOT + '\\n' + MESSAGE \n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0.8, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=500)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to improve it?\n",
    "\n",
    "Following the findings from [Min et al. (2022)](https://arxiv.org/abs/2202.12837), here are a few more tips about demonstrations/exemplars when doing few-shot:\n",
    "\n",
    "* \"the label space and the distribution of the input text specified by the demonstrations are both important (regardless of whether the labels are correct for individual inputs)\"\n",
    "* the format you use also plays a key role in performance, even if you just use random labels, this is much better than no labels at all.\n",
    "* additional results show that selecting random labels from a true distribution of labels (instead of a uniform distribution) also helps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
