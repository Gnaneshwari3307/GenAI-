{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Prompting\n",
    "\n",
    "Zero-shot prompting refers to a technique in prompt engineering where you provide a model with a task without any prior examples. The model is expected to understand and generate a response or complete the task purely based on the given instruction.\n",
    "\n",
    "In other words, the model is given \"zero\" prior training examples or demonstrations in the prompt and relies on its pre-trained knowledge to infer what is needed.\n",
    "\n",
    "## References:\n",
    "* [Wei et al. (2022)](https://arxiv.org/pdf/2109.01652.pdf): demonstrate how instruction tuning improves zero-shot learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fzero_shot.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': 'Act like you are an AI Software Requirements Analyst.\\nAnalyze the chatbot use case based on the following details:\\nGenerate a structured requirement analysis for NeuraBot, an AI Study Companion.  \\nList **Functional** and **Non-Functional** Requirements.  \\n- Functional: Describe key chatbot features.  \\n- Non-Functional: Include Security, Scalability, and User Experience.  \\nEnsure completeness and clarity.\\nProvide the response in a structured format with Functional and Non-Functional Requirements only.', 'stream': False, 'options': {'temperature': 0.3, 'num_ctx': 768, 'num_predict': 900}}\n",
      "**NeuraBot AI Study Companion Chatbot Use Case Analysis**\n",
      "\n",
      "**Functional Requirements:**\n",
      "\n",
      "1. **Welcome and Greeting**: The chatbot should be able to welcome users, ask for their name, and offer assistance with studying.\n",
      "2. **Subject Selection**: Users should be able to select a subject area (e.g., math, science, history) from a predefined list or enter a specific topic.\n",
      "3. **Question Bank**: The chatbot should have access to a vast question bank related to the selected subject area, which can be updated regularly.\n",
      "4. **Question-Answering**: Users should be able to ask questions, and the chatbot should provide accurate and relevant answers from its question bank.\n",
      "5. **Explanation and Clarification**: If users request explanations or clarification on a concept, the chatbot should provide detailed and concise responses.\n",
      "6. **Practice Exercises**: The chatbot should offer practice exercises based on user input, allowing them to test their understanding of the subject material.\n",
      "7. **Progress Tracking**: Users should be able to track their progress through completed questions, correct answers, and areas for improvement.\n",
      "8. **Personalized Learning Plans**: The chatbot should generate personalized learning plans based on user performance, suggesting topics to focus on and areas where they need more practice.\n",
      "9. **Feedback Mechanism**: Users should be able to provide feedback on the chatbot's responses, helping improve its accuracy and effectiveness over time.\n",
      "\n",
      "**Non-Functional Requirements:**\n",
      "\n",
      "1. **Security**:\n",
      " * Data encryption for all user interactions\n",
      " * Secure authentication and authorization mechanisms\n",
      " * Regular software updates and patches to prevent vulnerabilities\n",
      "2. **Scalability**:\n",
      " * Ability to handle a large volume of concurrent users without significant performance degradation\n",
      " * Scalable infrastructure to accommodate growing user base and increasing data storage needs\n",
      "3. **User Experience**:\n",
      " * Intuitive and user-friendly interface for easy navigation and interaction\n",
      " * Clear and concise language in responses, avoiding ambiguity or confusion\n",
      " * Responsive design for optimal performance on various devices and browsers\n",
      "Time taken: 50.157s\n"
     ]
    }
   ],
   "source": [
    "## Experimenting with Prompt Engineering for NeuraBot\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "# (1) Adjust the inbounding Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"\"\"Generate a structured requirement analysis for NeuraBot, an AI Study Companion.  \n",
    "List **Functional** and **Non-Functional** Requirements.  \n",
    "- Functional: Describe key chatbot features.  \n",
    "- Non-Functional: Include Security, Scalability, and User Experience.  \n",
    "Ensure completeness and clarity.\"\"\"\n",
    "\n",
    "# (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "TEMPLATE_BEFORE = \"Act like you are an AI Software Requirements Analyst.\\nAnalyze the chatbot use case based on the following details:\"\n",
    "TEMPLATE_AFTER = \"Provide the response in a structured format with Functional and Non-Functional Requirements only.\"\n",
    "\n",
    "# Construct the final Prompt\n",
    "PROMPT = TEMPLATE_BEFORE + '\\n' + MESSAGE + '\\n' + TEMPLATE_AFTER\n",
    "\n",
    "# (3) Configure the Model request, simulating Workflow Orchestration\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0.3,  # Lowered for a more structured response\n",
    "                         num_ctx=768,  # Increased context size for better requirement generation\n",
    "                         num_predict=900)  # Increased token output for detailed requirements\n",
    "\n",
    "# Send request to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: \n",
    "    print(f'Time taken: {time}s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## How to improve it?\n",
    "\n",
    "* **Use Clear and Concise Instructions**: Be specific about the task and desired format.\n",
    "    * Bad Prompt: “Summarize this.”\n",
    "    * Good Prompt: “Summarize this paragraph in one sentence.”\n",
    "* **Add Context**: Providing background can help the model interpret ambiguous prompts better.\n",
    "* **Specify Output Format**: If a particular structure is needed, describe it in the instruction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
